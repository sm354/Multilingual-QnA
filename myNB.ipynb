{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a77c3fb",
   "metadata": {},
   "source": [
    "### one time installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73e60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --id 1pb7gEkctrVrJA79EAIo7H7nuzD6uV1fW\n",
    "# !gdown --id 1oIeAE9HXXKWPcYa-AZ0ht5ef6sKe_Vh_\n",
    "# !gdown --id 10rAuIDvsYR2yDiCqP7GmYGPc-UmtLbJb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5a3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet transformers\n",
    "# !pip install --quiet datasets \n",
    "# !pip install --quiet SentencePiece\n",
    "# !pip install --quiet pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b18052",
   "metadata": {},
   "source": [
    "### libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0371301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef223314",
   "metadata": {},
   "source": [
    "### hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f9b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperparameters:\n",
    "    # tokenizer\n",
    "    tokenizer_name = \"deepset/xlm-roberta-large-squad2\" # model_name\n",
    "    max_len = 384 # maximum length of context and question in a datapoint\n",
    "    overlap_len = 128 # overlap between two parts of the context when it is split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a6df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150da3f",
   "metadata": {},
   "source": [
    "### data - understanding the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "969fda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hyperparams.tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9dc0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', encoding='utf-8')\n",
    "# test_df = pd.read_csv('test.csv')\n",
    "# sample_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b27f1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sklearn.utils.shuffle(train_df, random_state=4).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af9d2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[:2]\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "518bc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_answers(row):\n",
    "#     return {'answer_start': [row[0]], 'text': [row[1]]}\n",
    "\n",
    "# train_df['answers'] = train_df[['answer_start', 'answer_text']].apply(convert_answers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ef80aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train_df)):\n",
    "    if train_df.loc[idx,'language'] == \"hindi\" and len(tokenizer(train_df.loc[idx, 'context'], train_df.loc[idx, 'question'])['input_ids']) > hyperparams.max_len:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de9d7735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(train_df.loc[idx, 'question'])\n",
    "# print(train_df.loc[idx, 'context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa4791e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer(\n",
    "    list(train_df['question']), list(train_df['context']),\n",
    "    max_length=hyperparams.max_len, \n",
    "    truncation='only_second',\n",
    "    stride=hyperparams.overlap_len,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2ecb621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])\n",
      "62 62\n"
     ]
    }
   ],
   "source": [
    "print(out.keys())\n",
    "print(len(out['input_ids']), len(out['offset_mapping']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8d011103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(out['offset_mapping']))\n",
    "# for i in range(len(out['offset_mapping'])):\n",
    "#     print(len(out.sequence_ids(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee5f04a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> right\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token, tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7aaa628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(out['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36abbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.decode(out['input_ids'][0]))\n",
    "# print(tokenizer.decode(out['input_ids'][1]))\n",
    "# print(tokenizer.decode(out['input_ids'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4abcb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "map_sample2original = out.pop('overflow_to_sample_mapping')\n",
    "print(map_sample2original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd45cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe523d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37997b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feca53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "693b06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[:, 'context'] = data_df.loc[:, 'context'].apply(lambda sen : str(sen).strip())\n",
    "data_df.loc[:, 'question'] = data_df.loc[:, 'question'].apply(lambda sen : str(sen).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71471fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ரேடியம் எப்போது கண்டுபிடிக்கப்பட்டது?'\n",
      " 'हेलेन केलर की मृत्यु किस वर्ष में हुई थी?'\n",
      " 'खाद्य एवं औषधि प्रशासन का मुख्यालय कहाँ पर है?'\n",
      " 'क़ुस्तुंतुनिया शहर की स्थापना किस सम्राट ने की थी?'\n",
      " 'दिल्ली का क्षेत्रफल कितना है?' 'जापान का सबसे पहला राजा कौन था?'\n",
      " '२०१६ ग्रीष्मकालीन ओलम्पिक में कितने राष्ट्रों ने भाग लिया था?'\n",
      " 'ராமானுஜம் எங்கு பிறந்தார்?' 'ஆஸ்திரேலியாவில் எத்தனை மாநிலங்கள் உள்ளன?'\n",
      " 'विश्व पर्यावरण दिवस किस दिन मनाया जाता है?'\n",
      " 'ओटो एडुअर्ड लिओपोल्ड बिस्मार्क को किस वर्ष पेरिस में राजदूत बनाया गया?'\n",
      " 'किसने १९३२ में हिन्दुस्तान टाइम्स में कार्टून बनाने प्रारम्भ किए?'\n",
      " 'अन्ना हजारे का जन्म कहाँ हुआ था?'\n",
      " 'अभिनेत्री ब्लेक लिवली की माता का क्या नाम है?'\n",
      " 'இசுரேல் நாட்டின் பரப்பளவு என்ன?' 'रोमानिया की आधिकारिक भाषा क्या है?'\n",
      " 'யானையின் சராசரி ஆயுட்காலம் எவ்வளவு?'\n",
      " 'आई एन एस विक्रमादित्य को किस वर्ष भारतीय नौसेना में शामिल कर लिया गया?'\n",
      " 'உலகில் எத்தனை பாலூட்டி இனங்கள் உள்ளன?' 'அணு உலையை கண்டுபிடித்தவர் யார்?'\n",
      " 'सलमा हायेक के पति का नाम क्या है?'] 21\n"
     ]
    }
   ],
   "source": [
    "print(data_df['question'].values, len(data_df['question'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6576ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tokenized = tokenizer(\n",
    "    list(data_df['question']), list(data_df['context']),\n",
    "    max_length=hyperparams.max_len, \n",
    "    truncation='only_second',\n",
    "    stride=hyperparams.overlap_len,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1de2ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 290\n"
     ]
    }
   ],
   "source": [
    "print(len(data_df), len(data_tokenized['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642cfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a74cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac9f67d",
   "metadata": {},
   "source": [
    "### Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de06599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chaii(data_df, tokenizer, train, test):\n",
    "    # strip trailing and leading whitespaces in context, question, and (answer_text)?\n",
    "    data_df.loc[:, 'context'] = data_df.loc[:, 'context'].apply(lambda sen : str(sen).strip())\n",
    "    data_df.loc[:, 'question'] = data_df.loc[:, 'question'].apply(lambda sen : str(sen).strip())\n",
    "    if test == False:\n",
    "        data_df.loc[:, 'answer_text'] = data_df.loc[:, 'answer_text'].apply(lambda sen : str(sen).strip())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class chaii_ka_data(Dataset):\n",
    "    def __init__(self, data_df, tokenizer, train=True, test=False):\n",
    "        super(chaii_ka_data, self).__init__()\n",
    "        '''\n",
    "            train = True means train, train = False means val set; test = True means test set (without labels)\n",
    "            data_df is the pandas dataframe containing context, question, ...        \n",
    "        '''\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        \n",
    "        # tokenize data samples context;question, and create new samples if overflow\n",
    "        self.data = process_chaii(data_df, tokenizer, train, test)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1394a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3970894d",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082500c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2c87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2dc2a2",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad261610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72671c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7af9a1cc",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3a35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b368850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc0ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5773e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff96daa",
   "metadata": {},
   "source": [
    "### references\n",
    "1. https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb\n",
    "2. https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795681b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b71625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
